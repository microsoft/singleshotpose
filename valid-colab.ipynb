{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "valid.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1a2bbIfMrJb",
        "outputId": "81e2e161-1043-4efb-835c-091dd89e2a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Install previous version of torch\n",
        "!wget \"https://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\"\n",
        "!pip install torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "# Install previous version of scipy\n",
        "!pip uninstall scipy\n",
        "!pip install scipy==1.0\n",
        "# Restart Runtime if asked"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[31mERROR: -orchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuQoDxSR_qTK",
        "outputId": "7d6bb833-38ac-4805-81c0-a7c7ba9b1484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone \"https://github.com/microsoft/singleshotpose.git\" ss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ss'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Total 185 (delta 0), reused 0 (delta 0), pack-reused 185\u001b[K\n",
            "Receiving objects: 100% (185/185), 102.28 KiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvl_VA7MADvM",
        "outputId": "58b14610-46ae-4b0c-ff93-fe995e4567f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OOl28z9AGDY",
        "outputId": "151c75c8-5bda-40ce-804f-ba54196f0151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -O LINEMOD.tar --no-check-certificate \"https://onedrive.live.com/download?cid=05750EBEE1537631&resid=5750EBEE1537631%21135&authkey=AJRHFmZbcjXxTmI\"\n",
        "!wget -O backup.tar --no-check-certificate \"https://onedrive.live.com/download?cid=0C78B7DE6C569D7B&resid=C78B7DE6C569D7B%21191&authkey=AP183o4PlczZR78\"\n",
        "!wget -O multi_obj_pose_estimation/backup_multi.tar --no-check-certificate  \"https://onedrive.live.com/download?cid=05750EBEE1537631&resid=5750EBEE1537631%21136&authkey=AFQv01OSbvhGnoM\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-04 05:41:43--  https://onedrive.live.com/download?cid=05750EBEE1537631&resid=5750EBEE1537631%21135&authkey=AJRHFmZbcjXxTmI\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://yse3tg.dm.files.1drv.com/y4m23AZLRHCAeQd5LpchSnrT5pa17h0xFK9XZNi1GQjoFQEa2yxO-k6iNxM-90BgbHK83xzpMa1qPDj3TfLp4YAvjIWmasi4uuEqvFaC4QAptTPT2NHh116jbUeU5cvQWo91c3GVmx_3yc5wYcuienKNM0lQI1mciW4YcifK0ebD1MhwUmu2T8tduFI9n2OW_DRunlaq-pVKgk-T2dH7TbxCw/LINEMOD.tar?download&psid=1 [following]\n",
            "--2020-11-04 05:41:44--  https://yse3tg.dm.files.1drv.com/y4m23AZLRHCAeQd5LpchSnrT5pa17h0xFK9XZNi1GQjoFQEa2yxO-k6iNxM-90BgbHK83xzpMa1qPDj3TfLp4YAvjIWmasi4uuEqvFaC4QAptTPT2NHh116jbUeU5cvQWo91c3GVmx_3yc5wYcuienKNM0lQI1mciW4YcifK0ebD1MhwUmu2T8tduFI9n2OW_DRunlaq-pVKgk-T2dH7TbxCw/LINEMOD.tar?download&psid=1\n",
            "Resolving yse3tg.dm.files.1drv.com (yse3tg.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to yse3tg.dm.files.1drv.com (yse3tg.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1109913600 (1.0G) [application/octet-stream]\n",
            "Saving to: ‘LINEMOD.tar’\n",
            "\n",
            "LINEMOD.tar         100%[===================>]   1.03G  28.8MB/s    in 36s     \n",
            "\n",
            "2020-11-04 05:42:21 (29.2 MB/s) - ‘LINEMOD.tar’ saved [1109913600/1109913600]\n",
            "\n",
            "--2020-11-04 05:42:21--  https://onedrive.live.com/download?cid=0C78B7DE6C569D7B&resid=C78B7DE6C569D7B%21191&authkey=AP183o4PlczZR78\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lkusjq.by.files.1drv.com/y4mgKGgLg95YfiiYMr99PFNbA3mmdtzIqTAmH3WYGkVsL6WPGg8u_14hOFuGFXAaYdf9LJRfx_Iqs2mIUkdf0siaHQTno_SpsFyfV1dJzK2wn7KFhyev6S4tq090v1ZPJq4NRemhHKMpXZjIv-OetOJd3WXYhO3m2kjQPb5R0Sh0jP4uxluclah9Hn0rJ0jWOMWV8RlqK8xm-4DL_k9q36qtw/backup.tar?download&psid=1 [following]\n",
            "--2020-11-04 05:42:21--  https://lkusjq.by.files.1drv.com/y4mgKGgLg95YfiiYMr99PFNbA3mmdtzIqTAmH3WYGkVsL6WPGg8u_14hOFuGFXAaYdf9LJRfx_Iqs2mIUkdf0siaHQTno_SpsFyfV1dJzK2wn7KFhyev6S4tq090v1ZPJq4NRemhHKMpXZjIv-OetOJd3WXYhO3m2kjQPb5R0Sh0jP4uxluclah9Hn0rJ0jWOMWV8RlqK8xm-4DL_k9q36qtw/backup.tar?download&psid=1\n",
            "Resolving lkusjq.by.files.1drv.com (lkusjq.by.files.1drv.com)... 13.107.42.12\n",
            "Connecting to lkusjq.by.files.1drv.com (lkusjq.by.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4855183360 (4.5G) [application/octet-stream]\n",
            "Saving to: ‘backup.tar’\n",
            "\n",
            "backup.tar          100%[===================>]   4.52G  13.4MB/s    in 16m 34s \n",
            "\n",
            "2020-11-04 05:58:58 (4.66 MB/s) - ‘backup.tar’ saved [4855183360/4855183360]\n",
            "\n",
            "--2020-11-04 05:58:58--  https://onedrive.live.com/download?cid=05750EBEE1537631&resid=5750EBEE1537631%21136&authkey=AFQv01OSbvhGnoM\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://mowtng.dm.files.1drv.com/y4mDjpjMSlLEP7HvhozHpSAhUklgK8IaQzdVEX3Qa3qFFyk24NNHeAy-oMgcoMW1v5xw7A_PhaeptI7BJ-kEceO2XyGx3JGMQ-_4SRzXC40ECbKgtd2LHmXQhEfViYIfl0pkhq3bLfuuZaK2zHzi3Ykgr8zvzCwNaa6hda9wt-oRbDlhLgmP7GupviSbt8WyXyACyR4IwDn32xPn377yDvOUw/backup_multi.tar?download&psid=1 [following]\n",
            "--2020-11-04 05:58:59--  https://mowtng.dm.files.1drv.com/y4mDjpjMSlLEP7HvhozHpSAhUklgK8IaQzdVEX3Qa3qFFyk24NNHeAy-oMgcoMW1v5xw7A_PhaeptI7BJ-kEceO2XyGx3JGMQ-_4SRzXC40ECbKgtd2LHmXQhEfViYIfl0pkhq3bLfuuZaK2zHzi3Ykgr8zvzCwNaa6hda9wt-oRbDlhLgmP7GupviSbt8WyXyACyR4IwDn32xPn377yDvOUw/backup_multi.tar?download&psid=1\n",
            "Resolving mowtng.dm.files.1drv.com (mowtng.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to mowtng.dm.files.1drv.com (mowtng.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405708800 (387M) [application/octet-stream]\n",
            "Saving to: ‘multi_obj_pose_estimation/backup_multi.tar’\n",
            "\n",
            "multi_obj_pose_esti 100%[===================>] 386.91M  37.4MB/s    in 11s     \n",
            "\n",
            "2020-11-04 05:59:11 (35.8 MB/s) - ‘multi_obj_pose_estimation/backup_multi.tar’ saved [405708800/405708800]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJR1ZrLxOhCG"
      },
      "source": [
        "!tar xf LINEMOD.tar\n",
        "!tar xf backup.tar\n",
        "!tar xf multi_obj_pose_estimation/backup_multi.tar -C multi_obj_pose_estimation/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz-J25JDNrcS",
        "outputId": "59edbed6-63fa-486a-aa06-b76f776d632f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Weird but only way to get it to work\n",
        "!pip uninstall torchvision\n",
        "!pip install --no-deps torchvision\n",
        "!pip uninstall torchvision\n",
        "!pip install --no-deps torchvision==0.1.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchvision-0.1.6:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.1.6.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/_C.so\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/caltech.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/celeba.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/cityscapes.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/fakedata.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/flickr.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/hmdb51.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/imagenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/kinetics.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/omniglot.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/phototour.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/samplers/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/samplers/clip_sampler.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/sbd.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/sbu.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/semeion.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/stl10.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/svhn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/ucf101.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/usps.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/video_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/vision.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/datasets/voc.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/extension.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/io/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/io/_video_opt.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/io/video.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/backbone_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/faster_rcnn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/generalized_rcnn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/image_list.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/keypoint_rcnn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/mask_rcnn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/roi_heads.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/rpn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/detection/transform.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/googlenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/mnasnet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/mobilenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/googlenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/inception.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/mobilenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/resnet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/shufflenetv2.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/quantization/utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/segmentation/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/segmentation/_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/segmentation/deeplabv3.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/segmentation/fcn.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/segmentation/segmentation.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/shufflenetv2.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/squeezenet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/video/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/models/video/resnet.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/_register_onnx_ops.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/_utils.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/deform_conv.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/feature_pyramid_network.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/misc.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/new_empty_tensor.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/poolers.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/ps_roi_align.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/ps_roi_pool.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/roi_align.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/ops/roi_pool.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/__init__.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/_functional_video.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/_transforms_video.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_pil.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_tensor.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/version.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.1.6\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/43/aaa740c406b1832adc6ff9d5e71c23fd2af2ebd436c42d76d85809ec8be9/torchvision-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 246kB/s \n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.1\n",
            "Uninstalling torchvision-0.8.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.8.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libcudart.459720b2.so.10.2\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.8.1\n",
            "Collecting torchvision==0.1.6\n",
            "  Using cached https://files.pythonhosted.org/packages/ce/39/62f84a4b2aa94a12130857c3aeaa9ad5eebd279cc331bc9c9cbeb27acc27/torchvision-0.1.6-py3-none-any.whl\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRO-QmP5Rl0q",
        "outputId": "601596ea-1489-42ab-ccba-e7253a35a586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQfzzQIX_qTe"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import scipy.io\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "\n",
        "from darknet import Darknet\n",
        "import dataset\n",
        "from utils import *\n",
        "from MeshPly import MeshPly\n",
        "\n",
        "# Create new directory\n",
        "def makedirs(path):\n",
        "    if not os.path.exists( path ):\n",
        "        os.makedirs( path )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RxNI64N_qTs"
      },
      "source": [
        "def valid(datacfg, modelcfg, weightfile):\n",
        "    def truths_length(truths, max_num_gt=50):\n",
        "        for i in range(max_num_gt):\n",
        "            if truths[i][1] == 0:\n",
        "                return i\n",
        "\n",
        "    # Parse configuration files\n",
        "    data_options = read_data_cfg(datacfg)\n",
        "    valid_images = data_options['valid']\n",
        "    meshname     = data_options['mesh']\n",
        "    backupdir    = data_options['backup']\n",
        "    name         = data_options['name']\n",
        "    gpus         = data_options['gpus'] \n",
        "    fx           = float(data_options['fx'])\n",
        "    fy           = float(data_options['fy'])\n",
        "    u0           = float(data_options['u0'])\n",
        "    v0           = float(data_options['v0'])\n",
        "    im_width     = int(data_options['width'])\n",
        "    im_height    = int(data_options['height'])\n",
        "    if not os.path.exists(backupdir):\n",
        "        makedirs(backupdir)\n",
        "\n",
        "    # Parameters\n",
        "    seed = int(time.time())\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    save            = False\n",
        "    visualize       = True\n",
        "    testtime        = True\n",
        "    num_classes     = 1\n",
        "    testing_samples = 0.0\n",
        "    edges_corners = [[0, 1], [0, 2], [0, 4], [1, 3], [1, 5], [2, 3], [2, 6], [3, 7], [4, 5], [4, 6], [5, 7], [6, 7]]\n",
        "    if save:\n",
        "        makedirs(backupdir + '/test')\n",
        "        makedirs(backupdir + '/test/gt')\n",
        "        makedirs(backupdir + '/test/pr')\n",
        "    # To save\n",
        "    testing_error_trans = 0.0\n",
        "    testing_error_angle = 0.0\n",
        "    testing_error_pixel = 0.0\n",
        "    errs_2d             = []\n",
        "    errs_3d             = []\n",
        "    errs_trans          = []\n",
        "    errs_angle          = []\n",
        "    errs_corner2D       = []\n",
        "    preds_trans         = []\n",
        "    preds_rot           = []\n",
        "    preds_corners2D     = []\n",
        "    gts_trans           = []\n",
        "    gts_rot             = []\n",
        "    gts_corners2D       = []\n",
        "\n",
        "    # Read object model information, get 3D bounding box corners\n",
        "    mesh      = MeshPly(meshname)\n",
        "    vertices  = np.c_[np.array(mesh.vertices), np.ones((len(mesh.vertices), 1))].transpose()\n",
        "    corners3D = get_3D_corners(vertices)\n",
        "    try:\n",
        "        diam  = float(options['diam'])\n",
        "    except:\n",
        "        diam  = calc_pts_diameter(np.array(mesh.vertices))\n",
        "        \n",
        "    # Read intrinsic camera parameters\n",
        "    intrinsic_calibration = get_camera_intrinsic(u0, v0, fx, fy)\n",
        "\n",
        "    # Get validation file names\n",
        "    with open(valid_images) as fp:\n",
        "        tmp_files = fp.readlines()\n",
        "        valid_files = [item.rstrip() for item in tmp_files]\n",
        "    \n",
        "    # Specicy model, load pretrained weights, pass to GPU and set the module in evaluation mode\n",
        "    model = Darknet(modelcfg)\n",
        "    model.print_network()\n",
        "    model.load_weights(weightfile)\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    test_width    = model.test_width\n",
        "    test_height   = model.test_height\n",
        "    num_keypoints = model.num_keypoints \n",
        "    num_labels    = num_keypoints * 2 + 3\n",
        "\n",
        "    # Get the parser for the test dataset\n",
        "    valid_dataset = dataset.listDataset(valid_images, \n",
        "                                        shape=(test_width, test_height),\n",
        "                                        shuffle=False,\n",
        "                                        transform=transforms.Compose([transforms.ToTensor(),])\n",
        "                                        )\n",
        "\n",
        "    # Specify the number of workers for multiple processing, get the dataloader for the test dataset\n",
        "    kwargs = {'num_workers': 4, 'pin_memory': True}\n",
        "    test_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=False, **kwargs) \n",
        "\n",
        "    logging(\"   Testing {}...\".format(name))\n",
        "    logging(\"   Number of test samples: %d\" % len(test_loader.dataset))\n",
        "    # Iterate through test batches (Batch size for test data is 1)\n",
        "    count = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        \n",
        "        # Images\n",
        "        img = data[0, :, :, :]\n",
        "        img = img.numpy().squeeze()\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        \n",
        "        t1 = time.time()\n",
        "        # Pass data to GPU\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "        # Wrap tensors in Variable class, set volatile=True for inference mode and to use minimal memory during inference\n",
        "        data = Variable(data, volatile=True)\n",
        "        t2 = time.time()\n",
        "        # Forward pass\n",
        "        output = model(data).data  \n",
        "        t3 = time.time()\n",
        "        # Using confidence threshold, eliminate low-confidence predictions\n",
        "        all_boxes = get_region_boxes(output, num_classes, num_keypoints)        \n",
        "        t4 = time.time()\n",
        "        # Evaluation\n",
        "        # Iterate through all batch elements\n",
        "        for box_pr, target in zip([all_boxes], [target[0]]):\n",
        "            # For each image, get all the targets (for multiple object pose estimation, there might be more than 1 target per image)\n",
        "            truths = target.view(-1, num_keypoints*2+3)\n",
        "            # Get how many objects are present in the scene\n",
        "            num_gts    = truths_length(truths)\n",
        "            # Iterate through each ground-truth object\n",
        "            for k in range(num_gts):\n",
        "                box_gt = list()\n",
        "                for j in range(1, 2*num_keypoints+1):\n",
        "                    box_gt.append(truths[k][j])\n",
        "                box_gt.extend([1.0, 1.0])\n",
        "                box_gt.append(truths[k][0])\n",
        "\n",
        "                # Denormalize the corner predictions \n",
        "                corners2D_gt = np.array(np.reshape(box_gt[:18], [9, 2]), dtype='float32')\n",
        "                corners2D_pr = np.array(np.reshape(box_pr[:18], [9, 2]), dtype='float32')\n",
        "                corners2D_gt[:, 0] = corners2D_gt[:, 0] * im_width\n",
        "                corners2D_gt[:, 1] = corners2D_gt[:, 1] * im_height          \n",
        "                corners2D_pr[:, 0] = corners2D_pr[:, 0] * im_width\n",
        "                corners2D_pr[:, 1] = corners2D_pr[:, 1] * im_height\n",
        "                preds_corners2D.append(corners2D_pr)\n",
        "                gts_corners2D.append(corners2D_gt)\n",
        "\n",
        "                # Compute corner prediction error\n",
        "                corner_norm = np.linalg.norm(corners2D_gt - corners2D_pr, axis=1)\n",
        "                corner_dist = np.mean(corner_norm)\n",
        "                errs_corner2D.append(corner_dist)\n",
        "                \n",
        "                # Compute [R|t] by pnp\n",
        "                R_gt, t_gt = pnp(np.array(np.transpose(np.concatenate((np.zeros((3, 1)), corners3D[:3, :]), axis=1)), dtype='float32'),  corners2D_gt, np.array(intrinsic_calibration, dtype='float32'))\n",
        "                R_pr, t_pr = pnp(np.array(np.transpose(np.concatenate((np.zeros((3, 1)), corners3D[:3, :]), axis=1)), dtype='float32'),  corners2D_pr, np.array(intrinsic_calibration, dtype='float32'))\n",
        "                \n",
        "                # Compute translation error\n",
        "                trans_dist   = np.sqrt(np.sum(np.square(t_gt - t_pr)))\n",
        "                errs_trans.append(trans_dist)\n",
        "                \n",
        "                # Compute angle error\n",
        "                angle_dist   = calcAngularDistance(R_gt, R_pr)\n",
        "                errs_angle.append(angle_dist)\n",
        "                \n",
        "                # Compute pixel error\n",
        "                Rt_gt        = np.concatenate((R_gt, t_gt), axis=1)\n",
        "                Rt_pr        = np.concatenate((R_pr, t_pr), axis=1)\n",
        "                proj_2d_gt   = compute_projection(vertices, Rt_gt, intrinsic_calibration)\n",
        "                proj_2d_pred = compute_projection(vertices, Rt_pr, intrinsic_calibration) \n",
        "                proj_corners_gt = np.transpose(compute_projection(corners3D, Rt_gt, intrinsic_calibration)) \n",
        "                proj_corners_pr = np.transpose(compute_projection(corners3D, Rt_pr, intrinsic_calibration)) \n",
        "                norm         = np.linalg.norm(proj_2d_gt - proj_2d_pred, axis=0)\n",
        "                pixel_dist   = np.mean(norm)\n",
        "                errs_2d.append(pixel_dist)\n",
        "\n",
        "                if visualize:\n",
        "                    # Visualize\n",
        "                    plt.xlim((0, im_width))\n",
        "                    plt.ylim((0, im_height))\n",
        "                    plt.imshow(scipy.misc.imresize(img, (im_height, im_width)))\n",
        "                    # Projections\n",
        "                    for edge in edges_corners:\n",
        "                        plt.plot(proj_corners_gt[edge, 0], proj_corners_gt[edge, 1], color='g', linewidth=3.0)\n",
        "                        plt.plot(proj_corners_pr[edge, 0], proj_corners_pr[edge, 1], color='b', linewidth=3.0)\n",
        "                    plt.gca().invert_yaxis()\n",
        "                    plt.show()\n",
        "                \n",
        "                # Compute 3D distances\n",
        "                transform_3d_gt   = compute_transformation(vertices, Rt_gt) \n",
        "                transform_3d_pred = compute_transformation(vertices, Rt_pr)  \n",
        "                norm3d            = np.linalg.norm(transform_3d_gt - transform_3d_pred, axis=0)\n",
        "                vertex_dist       = np.mean(norm3d)    \n",
        "                errs_3d.append(vertex_dist)  \n",
        "\n",
        "                # Sum errors\n",
        "                testing_error_trans  += trans_dist\n",
        "                testing_error_angle  += angle_dist\n",
        "                testing_error_pixel  += pixel_dist\n",
        "                testing_samples      += 1\n",
        "                count = count + 1\n",
        "\n",
        "                if save:\n",
        "                    preds_trans.append(t_pr)\n",
        "                    gts_trans.append(t_gt)\n",
        "                    preds_rot.append(R_pr)\n",
        "                    gts_rot.append(R_gt)\n",
        "\n",
        "                    np.savetxt(backupdir + '/test/gt/R_' + valid_files[count][-8:-3] + 'txt', np.array(R_gt, dtype='float32'))\n",
        "                    np.savetxt(backupdir + '/test/gt/t_' + valid_files[count][-8:-3] + 'txt', np.array(t_gt, dtype='float32'))\n",
        "                    np.savetxt(backupdir + '/test/pr/R_' + valid_files[count][-8:-3] + 'txt', np.array(R_pr, dtype='float32'))\n",
        "                    np.savetxt(backupdir + '/test/pr/t_' + valid_files[count][-8:-3] + 'txt', np.array(t_pr, dtype='float32'))\n",
        "                    np.savetxt(backupdir + '/test/gt/corners_' + valid_files[count][-8:-3] + 'txt', np.array(corners2D_gt, dtype='float32'))\n",
        "                    np.savetxt(backupdir + '/test/pr/corners_' + valid_files[count][-8:-3] + 'txt', np.array(corners2D_pr, dtype='float32'))\n",
        "\n",
        "\n",
        "        t5 = time.time()\n",
        "\n",
        "    # Compute 2D projection error, 6D pose error, 5cm5degree error\n",
        "    px_threshold = 5 # 5 pixel threshold for 2D reprojection error is standard in recent sota 6D object pose estimation works \n",
        "    eps          = 1e-5\n",
        "    acc          = len(np.where(np.array(errs_2d) <= px_threshold)[0]) * 100. / (len(errs_2d)+eps)\n",
        "    acc5cm5deg   = len(np.where((np.array(errs_trans) <= 0.05) & (np.array(errs_angle) <= 5))[0]) * 100. / (len(errs_trans)+eps)\n",
        "    acc3d10      = len(np.where(np.array(errs_3d) <= diam * 0.1)[0]) * 100. / (len(errs_3d)+eps)\n",
        "    acc5cm5deg   = len(np.where((np.array(errs_trans) <= 0.05) & (np.array(errs_angle) <= 5))[0]) * 100. / (len(errs_trans)+eps)\n",
        "    corner_acc   = len(np.where(np.array(errs_corner2D) <= px_threshold)[0]) * 100. / (len(errs_corner2D)+eps)\n",
        "    mean_err_2d  = np.mean(errs_2d)\n",
        "    mean_corner_err_2d = np.mean(errs_corner2D)\n",
        "    nts = float(testing_samples)\n",
        "\n",
        "    if testtime:\n",
        "        print('-----------------------------------')\n",
        "        print('  tensor to cuda : %f' % (t2 - t1))\n",
        "        print('    forward pass : %f' % (t3 - t2))\n",
        "        print('get_region_boxes : %f' % (t4 - t3))\n",
        "        print(' prediction time : %f' % (t4 - t1))\n",
        "        print('            eval : %f' % (t5 - t4))\n",
        "        print('-----------------------------------')\n",
        "\n",
        "    # Print test statistics\n",
        "    logging('Results of {}'.format(name))\n",
        "    logging('   Acc using {} px 2D Projection = {:.2f}%'.format(px_threshold, acc))\n",
        "    logging('   Acc using 10% threshold - {} vx 3D Transformation = {:.2f}%'.format(diam * 0.1, acc3d10))\n",
        "    logging('   Acc using 5 cm 5 degree metric = {:.2f}%'.format(acc5cm5deg))\n",
        "    logging(\"   Mean 2D pixel error is %f, Mean vertex error is %f, mean corner error is %f\" % (mean_err_2d, np.mean(errs_3d), mean_corner_err_2d))\n",
        "    logging('   Translation error: %f m, angle error: %f degree, pixel error: % f pix' % (testing_error_trans/nts, testing_error_angle/nts, testing_error_pixel/nts) )\n",
        "\n",
        "    if save:\n",
        "        predfile = backupdir + '/predictions_linemod_' + name +  '.mat'\n",
        "        scipy.io.savemat(predfile, {'R_gts': gts_rot, 't_gts':gts_trans, 'corner_gts': gts_corners2D, 'R_prs': preds_rot, 't_prs':preds_trans, 'corner_prs': preds_corners2D})\n",
        "\n",
        "datacfg    = 'cfg/ape.data'\n",
        "modelcfg   = 'cfg/yolo-pose.cfg'\n",
        "weightfile = 'backup/ape/model_backup.weights'\n",
        "valid(datacfg, modelcfg, weightfile)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}